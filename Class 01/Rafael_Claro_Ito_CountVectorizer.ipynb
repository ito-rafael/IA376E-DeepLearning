{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rafael Claro Ito - CountVectorizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpHsn58xAL5J",
        "colab_type": "text"
      },
      "source": [
        "# Nome: Rafael Ito\n",
        "\n",
        "Objetivo desse experimento é conhecer o CountVectorizer do scikit-learn, usando-o numa pequena amostra do dataset IMDB e codificando funções equivalente no Python.\n",
        "\n",
        "Funções a serem implementadas:\n",
        "\n",
        "1. vocab = build_vocab(corpus)\n",
        "2. corpus_tok = tokenizer(corpus, vocab)\n",
        "3. doc_term = feature(corpus_tok)\n",
        "\n",
        "Enquanto está depurando o seu programa, utilize um corpus bem pequeno, com poucos exemplos e depois de depurado, rode ele nos 1000 exemplos do imdb_sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQzaT1ORJbYr",
        "colab_type": "text"
      },
      "source": [
        "## Usando o exemplo do scikit-learn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTTrYKgj__xP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mep9IKItA0z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?',\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-1Fk8I5A399",
        "colab_type": "code",
        "outputId": "cd2e9591-6467-4f40-9a26-04c87604c8ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "vocab = vectorizer.get_feature_names()\n",
        "print(vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGgd8CqKUWvs",
        "colab_type": "text"
      },
      "source": [
        "## Mostrando o Document-term também denominado de \"bag of words\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exIVtJa9A63-",
        "colab_type": "code",
        "outputId": "55f2e438-79fb-49a5-d226-db15dc7a886f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "print(X.toarray())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Bp1wBFHgE0",
        "colab_type": "text"
      },
      "source": [
        "## Minha implementação de um tokenizador simples usando o vocabulário já extraído pelo scikit-learn\n",
        "\n",
        "Primeira versão: usando for simples\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPqdi8lrA72N",
        "colab_type": "code",
        "outputId": "bd84b698-7ae1-4fde-e4c8-ae2247731b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "list_word_based = []\n",
        "list_token_based = []\n",
        "for amostra in corpus:\n",
        "    amostra = re.sub(r'\\W',' ',amostra).strip().lower()\n",
        "    list_words = amostra.split(' ')\n",
        "    list_tokens = []\n",
        "    for word in list_words:\n",
        "        list_tokens.append(vocab.index(word))\n",
        "    list_word_based.append(list_words)\n",
        "    list_token_based.append(list_tokens)\n",
        "list_word_based, list_token_based"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['this', 'is', 'the', 'first', 'document'],\n",
              "  ['this', 'document', 'is', 'the', 'second', 'document'],\n",
              "  ['and', 'this', 'is', 'the', 'third', 'one'],\n",
              "  ['is', 'this', 'the', 'first', 'document']],\n",
              " [[8, 3, 6, 2, 1], [8, 1, 3, 6, 5, 1], [0, 8, 3, 6, 7, 4], [3, 8, 6, 2, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anxC0M_9Hkpt",
        "colab_type": "text"
      },
      "source": [
        "Segunda versão: for com list comprehension\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEa-Q2edBFNp",
        "colab_type": "code",
        "outputId": "2f3ab87d-e5c5-4e8f-cd4c-f2cfd6abad5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "list_word_based = []\n",
        "list_token_based = []\n",
        "for amostra in corpus:\n",
        "    amostra = re.sub(r'\\W',' ',amostra).strip().lower()\n",
        "    list_words = amostra.split(' ')\n",
        "    list_tokens = [vocab.index(word)   for word in list_words]\n",
        "    list_word_based.append(list_words)\n",
        "    list_token_based.append(list_tokens)\n",
        "list_word_based, list_token_based"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['this', 'is', 'the', 'first', 'document'],\n",
              "  ['this', 'document', 'is', 'the', 'second', 'document'],\n",
              "  ['and', 'this', 'is', 'the', 'third', 'one'],\n",
              "  ['is', 'this', 'the', 'first', 'document']],\n",
              " [[8, 3, 6, 2, 1], [8, 1, 3, 6, 5, 1], [0, 8, 3, 6, 7, 4], [3, 8, 6, 2, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThzSeNEKIm6J",
        "colab_type": "text"
      },
      "source": [
        "# Download do dataset do IMDB_sample (apenas 1000 exemplos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvMu6ILcKJEd",
        "colab_type": "text"
      },
      "source": [
        "O dataset está sendo carregado dos datasets disponibilizados pelo curso fast.ai: https://course.fast.ai/datasets.html\n",
        "\n",
        "O comando wget busca o arquivo imdb.tgz\n",
        "O comando tar descomprime o arquivo no diretório local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc80_T9eCfgc",
        "colab_type": "code",
        "outputId": "53d61698-7caa-4d38-9228-72bb6ae970d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "!wget -nc http://files.fast.ai/data/examples/imdb_sample.tgz\n",
        "!tar -xzf imdb_sample.tgz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘imdb_sample.tgz’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilrnRFUdKmcg",
        "colab_type": "text"
      },
      "source": [
        "O diretório descomprimido tem um arquivo no formato csv:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1R95J16Dw0Q",
        "colab_type": "code",
        "outputId": "0a05b898-99b2-4c35-a129-149281859dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "!ls imdb_sample"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "texts.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5bvG8ilJkqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFf1MI9XRNdN",
        "colab_type": "code",
        "outputId": "d36dc1c5-4f8d-42a4-d90e-3d6a994ad9e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "df = pd.read_csv('imdb_sample/texts.csv')\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRGSLFezRXRV",
        "colab_type": "code",
        "outputId": "60a8e318-5164-4443-acff-d4e48918e4fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>is_valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>This is a extremely well-made film. The acting...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>Every once in a long while a movie will come a...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>Name just says it all. I watched this movie wi...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>This movie succeeds at being one of the most u...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                               text  is_valid\n",
              "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
              "1  positive  This is a extremely well-made film. The acting...     False\n",
              "2  negative  Every once in a long while a movie will come a...     False\n",
              "3  positive  Name just says it all. I watched this movie wi...     False\n",
              "4  negative  This movie succeeds at being one of the most u...     False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37_bl68zSzEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLkYLMkhwtHB",
        "colab_type": "text"
      },
      "source": [
        "## **Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fsv28sGwwfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_processing(corpus):\n",
        "    corpus_pp = []\n",
        "    for sentence in corpus:\n",
        "        new_sentence = sentence.lower()                             # convert to lowercase\n",
        "        new_sentence = re.sub(\"[^\\w]\", \" \",  new_sentence).split()  # match word characters [a-zA-Z0-9_]\n",
        "        corpus_pp.append(new_sentence)\n",
        "    return corpus_pp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4HM47laxHTe",
        "colab_type": "code",
        "outputId": "23abcd5a-8c7b-4169-bc83-92df4dac0d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "corpus_pp = pre_processing(corpus)\n",
        "corpus_pp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['this', 'is', 'the', 'first', 'document'],\n",
              " ['this', 'document', 'is', 'the', 'second', 'document'],\n",
              " ['and', 'this', 'is', 'the', 'third', 'one'],\n",
              " ['is', 'this', 'the', 'first', 'document']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc7yjrJork5j",
        "colab_type": "text"
      },
      "source": [
        "## **Vocabulary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmkJNmysr77m",
        "colab_type": "text"
      },
      "source": [
        "### function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CQ9ou2sn4o9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab(corpus):\n",
        "    vocab = \" \".join(corpus)                        # join elements\n",
        "    vocab = vocab.lower()                           # convert to lowercase\n",
        "    vocab = re.sub(\"[^\\w]\", \" \",  vocab).split()    # match word characters [a-zA-Z0-9_]\n",
        "    vocab = list(set(vocab))                        # remove duplicates\n",
        "    vocab.sort()                                    # sort elements\n",
        "    return vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dtgYyxRr9fA",
        "colab_type": "text"
      },
      "source": [
        "### testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVFismS0o_Rg",
        "colab_type": "code",
        "outputId": "8137e7b9-5e51-47e3-b714-cc5e78378dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "vocab = build_vocab(corpus)\n",
        "vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbNxTYRur_9m",
        "colab_type": "text"
      },
      "source": [
        "### comparing with scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIj5fYn0saZV",
        "colab_type": "code",
        "outputId": "42a2e6eb-e859-4350-e8cf-6702e62b9ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "sk_vocab = vectorizer.get_feature_names()\n",
        "print(sk_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MPtfkHc08Dh",
        "colab_type": "code",
        "outputId": "6c2b64be-8160-41c4-b4e8-0f59a8d0db83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "vocab == sk_vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnsywqchru2U",
        "colab_type": "text"
      },
      "source": [
        "## **Tokenizer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ONP7dmBhsIhX"
      },
      "source": [
        "### function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HNidTCYSzLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer(corpus, vocab):\n",
        "    # first, a dictionary is created with the keys being the words in vocab, and the values being the index\n",
        "    dict = {vocab[i] : i for i in range(len(vocab))}\n",
        "    corpus_pp = pre_processing(corpus)\n",
        "    corpus_tok = []\n",
        "    for idx, sentence in enumerate(corpus_pp):\n",
        "        tokens = [dict[word] for word in sentence]\n",
        "        corpus_tok.append(tokens)\n",
        "    return corpus_tok"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rcLDCV95sIhh"
      },
      "source": [
        "### testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7SYEI2Sp4mq",
        "colab_type": "code",
        "outputId": "cb8ed942-c5e4-4c20-bb00-f9ca22fb5250",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "corpus_tok = tokenizer(corpus, vocab)\n",
        "corpus_tok"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 3, 6, 2, 1], [8, 1, 3, 6, 5, 1], [0, 8, 3, 6, 7, 4], [3, 8, 6, 2, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHsp7csHr0mp",
        "colab_type": "text"
      },
      "source": [
        "## **Bag of Words**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gHALEJl_sMbg"
      },
      "source": [
        "### function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3sAja2tp4ro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature(corpus_tok):\n",
        "    # create tensor with zeros of the correct size\n",
        "    size = max([max(sublist) for sublist in corpus_tok]) + 1\n",
        "    doc_term = torch.zeros(len(corpus_tok), size, dtype=torch.int64)\n",
        "    for line, tok in enumerate(corpus_tok):\n",
        "        for column in tok:\n",
        "            doc_term[line][column] += 1\n",
        "    return doc_term"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IRN_2Ll9sMbk"
      },
      "source": [
        "### testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXUvtZufp4jy",
        "colab_type": "code",
        "outputId": "4dabac5b-c5ed-49a1-f8f5-8fbdbe184d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "doc_term = feature(corpus_tok)\n",
        "doc_term"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
              "        [0, 2, 0, 1, 0, 1, 1, 0, 1],\n",
              "        [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
              "        [0, 1, 1, 1, 0, 0, 1, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VvRaHOG4sMbm"
      },
      "source": [
        "### comparing with scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuHmmtFgp4gt",
        "colab_type": "code",
        "outputId": "1569913c-a0d1-4966-dfc5-0b3a832ea369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "print(X.toarray())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxUc-dGN-UC4",
        "colab_type": "code",
        "outputId": "0fc4c357-11ce-4a61-d39d-0473ad939157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "doc_term_np = doc_term.numpy()\n",
        "print(doc_term_np)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hre52MbLrZv1",
        "colab_type": "code",
        "outputId": "0b073c48-a507-41d0-f6fe-029cb48ce77d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "np.array_equal(doc_term_np, X.toarray())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBt5yVeo_O5P",
        "colab_type": "text"
      },
      "source": [
        "## **IMDb**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8pZTqTRFcis",
        "colab_type": "text"
      },
      "source": [
        "### Filter data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSX4e9IE5Y1W",
        "colab_type": "code",
        "outputId": "390436a1-22e8-4239-ae6c-eb4227707923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# getting only the 'text' column\n",
        "imdb_corpus = df['text']\n",
        "imdb_corpus.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiOGwCQ7E8pt",
        "colab_type": "text"
      },
      "source": [
        "### Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J63qu5iT_nCL",
        "colab_type": "code",
        "outputId": "1ef81633-2c8e-4c73-ddf9-1a6f20cbd694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# build_vocab\n",
        "imdb_vocab = build_vocab(imdb_corpus)\n",
        "len(imdb_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18705"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liJPTfx6FJuk",
        "colab_type": "code",
        "outputId": "1f1ad80a-fb70-4c94-ebc0-c3eb5b6a4c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# scikit-learn comparison\n",
        "vectorizer = CountVectorizer()\n",
        "Y = vectorizer.fit_transform(imdb_corpus)\n",
        "sk_imdb_vocab = vectorizer.get_feature_names()\n",
        "len(sk_imdb_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18668"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-gJrogUFBVl",
        "colab_type": "text"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDK7fb1I_nF7",
        "colab_type": "code",
        "outputId": "1d00c3ff-7613-46bd-81ae-f4a7855ed4c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "imdb_corpus_tok = tokenizer(imdb_corpus, imdb_vocab)\n",
        "len(imdb_corpus_tok)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGy-l0ELFCxn",
        "colab_type": "text"
      },
      "source": [
        "### Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVSvEMcLBlLA",
        "colab_type": "code",
        "outputId": "75ae772c-e882-441a-f48c-8eab6724130b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "imdb_doc_term = feature(imdb_corpus_tok)\n",
        "imdb_doc_term.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 18705])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "efe9a49b-ce95-4f6e-ef83-75dbcbe0b544",
        "id": "CAOYR0UEFs0p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# scikit-learn comparison\n",
        "Y.toarray().shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 18668)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etI6hUK6GJXy",
        "colab_type": "text"
      },
      "source": [
        "### Comments:\n",
        "O tamanho do vocabulário com a implementação do scikit-learn foi ligeiramente menor do que a minha implementação (scikit-learn: 18668, minha implementação: 18705). Isso ocorre devido a diferença de filtragem inicial. No meu caso, apenas troquei os caracteres para minúsculo e depois selecionei palavras que começam com os caracteres [a-zA-Z0-9_]."
      ]
    }
  ]
}